# LLM Models Configuration for Consistency Evaluation

# Models to use for consistency evaluation (Part 3)
evaluation_models:
  - name: "gpt-4o-mini"
    provider: "openai"
    model_id: "gpt-4o-mini"
    temperature: 0.0
    max_tokens: 2000
    enabled: true

  - name: "claude-3-haiku"
    provider: "anthropic"
    model_id: "claude-3-haiku-20240307"
    temperature: 0.0
    max_tokens: 2000
    enabled: true

  - name: "llama3.2"
    provider: "ollama"
    model_id: "llama3.2"
    temperature: 0.0
    max_tokens: 2000
    enabled: false  # Enable if Ollama is installed locally

  - name: "gemini-flash"
    provider: "google"
    model_id: "gemini-1.5-flash"
    temperature: 0.0
    max_tokens: 2000
    enabled: false  # Enable with Google API key

# Consistency Scoring Configuration
consistency:
  method: "semantic_similarity"  # Options: exact_match, semantic_similarity, llm_judge
  similarity_threshold: 0.85
  embedding_model: "all-MiniLM-L6-v2"

# Correctness Scoring Configuration
correctness:
  method: "semantic_similarity"  # Options: exact_match, semantic_similarity, llm_judge
  similarity_threshold: 0.90

# Execution Settings
execution:
  parallel: true
  max_concurrent: 3
  timeout_seconds: 60
  retry_count: 2
  retry_delay: 5
