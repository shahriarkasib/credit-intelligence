# PostgreSQL Setup Guide for Credit Intelligence

This guide explains how to set up PostgreSQL on Heroku for Credit Intelligence logs retention.

## Why PostgreSQL?

Previously, all logs were stored in Google Sheets which had limitations:
- Schema changes were risky and could lose data
- Not scalable for viewing/searching large datasets
- Google Sheets UI is hard to use for complex queries
- Viewing a single run across multiple tabs was difficult

PostgreSQL provides:
- Proper SQL querying with JOINs and aggregations
- Monthly partitioning for efficient data retention
- Connection pooling for scalability
- Native support for JSON/JSONB columns
- Easy backup and restore

## Architecture Overview

```
┌─────────────────────────────────────────────────────────────┐
│                    Storage Layer                            │
├─────────────────┬─────────────────┬───────────────────────┤
│    MongoDB      │   PostgreSQL    │   Google Sheets       │
│   (Primary)     │   (Analytics)   │   (Legacy/Audit)      │
├─────────────────┼─────────────────┼───────────────────────┤
│ - run_summaries │ - runs          │ - runs                │
│ - assessments   │ - wf_*          │ - llm_calls           │
│ - llm_calls     │ - eval_*        │ - tool_calls          │
│ - api_keys      │ - sys_api_keys  │ - evaluations         │
└─────────────────┴─────────────────┴───────────────────────┘
```

## Table Naming Convention

| Prefix | Purpose | Examples |
|--------|---------|----------|
| (none) | Core run data | `runs` |
| `wf_` | Workflow logs | `wf_llm_calls`, `wf_tool_calls`, `wf_langgraph_events` |
| `eval_` | Evaluation results | `eval_evaluations`, `eval_tool_selections`, `eval_coalition` |
| `sys_` | System data | `sys_api_keys` |

## Heroku Setup Instructions

### Step 1: Add Heroku Postgres

```bash
# Add the Mini plan (free tier with 10K rows)
heroku addons:create heroku-postgresql:mini -a credit-intelligence

# Or Essential-0 plan ($5/mo, 10M rows, better for production)
heroku addons:create heroku-postgresql:essential-0 -a credit-intelligence
```

### Step 2: Verify the Database URL

```bash
# Get the DATABASE_URL
heroku config:get DATABASE_URL -a credit-intelligence

# It will look like:
# postgres://username:password@host:5432/database_name
```

### Step 3: Initialize the Schema

Option A: Via API (after deploying):
```bash
curl -X POST https://credit-intelligence-096cc99c71eb.herokuapp.com/pg/init
```

Option B: Via CLI (locally):
```bash
# Set the DATABASE_URL locally
export DATABASE_URL="postgres://..."

# Run initialization script
python scripts/init_postgres.py --months 12
```

### Step 4: Verify the Setup

```bash
# Check status
curl https://credit-intelligence-096cc99c71eb.herokuapp.com/pg/status

# Expected response:
{
  "available": true,
  "connected": true,
  "statistics": {
    "total_runs": 0,
    "by_status": {},
    "by_risk_level": {},
    "averages": {...}
  }
}
```

## Tables and Schema

### Core Table: `runs`

```sql
CREATE TABLE runs (
  id BIGSERIAL,
  run_id VARCHAR(64) NOT NULL,
  company_name VARCHAR(255),
  status VARCHAR(50),
  risk_level VARCHAR(50),
  credit_score INTEGER,
  confidence DECIMAL(5,4),
  reasoning TEXT,
  overall_score DECIMAL(5,4),
  final_decision VARCHAR(50),
  tools_used JSONB,
  agents_used JSONB,
  started_at TIMESTAMPTZ,
  completed_at TIMESTAMPTZ,
  duration_ms DECIMAL(15,3),
  total_tokens INTEGER,
  total_cost DECIMAL(12,6),
  timestamp TIMESTAMPTZ NOT NULL,
  PRIMARY KEY (id, timestamp)
) PARTITION BY RANGE (timestamp);
```

### Workflow Tables (wf_*)

| Table | Description |
|-------|-------------|
| `wf_llm_calls` | All LLM API calls with prompts, responses, tokens, costs |
| `wf_tool_calls` | Tool executions with inputs, outputs, timing |
| `wf_langgraph_events` | LangGraph workflow events and state changes |
| `wf_plans` | Task plans generated by the planner |
| `wf_prompts` | Prompts used with variables |
| `wf_data_sources` | Data fetched from external sources |
| `wf_assessments` | Credit assessments produced |

### Evaluation Tables (eval_*)

| Table | Description |
|-------|-------------|
| `eval_evaluations` | General evaluation scores |
| `eval_tool_selections` | Tool selection precision/recall/F1 |
| `eval_consistency_scores` | Cross-run consistency metrics |
| `eval_cross_model` | Multi-model comparison results |
| `eval_llm_judge` | LLM judge evaluation results |
| `eval_agent_metrics` | Agent efficiency metrics |
| `eval_coalition` | Coalition evaluation results |
| `eval_log_tests` | Log verification results |

## Data Retention

### Automatic Partitioning

Tables are partitioned by month. Example:
```
runs_2026_01
runs_2026_02
runs_2026_03
...
runs_2026_12
```

### Applying Retention Policy

Drop old partitions to manage storage:

```bash
# Via API - keep last 3 months
curl -X POST "https://your-app.herokuapp.com/pg/retention?months_to_keep=3"

# Via CLI
python scripts/init_postgres.py --drop-old --retention 3
```

### Weekly Retention Schedule

Set up a Heroku Scheduler to run weekly:

```bash
# Add Heroku Scheduler
heroku addons:create scheduler:standard -a credit-intelligence

# Configure job (in Heroku dashboard):
# Command: python scripts/init_postgres.py --drop-old --retention 4
# Frequency: Weekly
```

## API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/pg/status` | GET | Connection status and statistics |
| `/pg/init` | POST | Initialize schema with partitions |
| `/pg/runs` | GET | List runs (supports `limit`, `company_name`) |
| `/pg/runs/{run_id}` | GET | Get comprehensive run details |
| `/pg/statistics` | GET | Aggregate statistics |
| `/pg/retention` | POST | Apply retention policy |
| `/pg/query/{table_name}` | GET | Query any table |

## Querying Examples

### Get Recent Runs
```bash
curl "https://your-app.herokuapp.com/pg/runs?limit=10"
```

### Get Run Details
```bash
curl "https://your-app.herokuapp.com/pg/runs/abc-123-def"
```

### Query Specific Table
```bash
# Get LLM calls for a run
curl "https://your-app.herokuapp.com/pg/query/wf_llm_calls?run_id=abc-123-def&limit=50"

# Get all evaluations
curl "https://your-app.herokuapp.com/pg/query/eval_evaluations?limit=100"
```

## Connecting with pgAdmin

1. Get credentials from Heroku:
```bash
heroku pg:credentials:url DATABASE -a credit-intelligence
```

2. In pgAdmin, create new server:
   - Host: (from credentials)
   - Port: 5432
   - Database: (from credentials)
   - Username: (from credentials)
   - Password: (from credentials)
   - SSL Mode: Require

## SQL Views for Analysis

Create views for common queries:

```sql
-- All data for a single run
CREATE VIEW v_run_complete AS
SELECT
  r.*,
  (SELECT json_agg(l.*) FROM wf_llm_calls l WHERE l.run_id = r.run_id) as llm_calls,
  (SELECT json_agg(t.*) FROM wf_tool_calls t WHERE t.run_id = r.run_id) as tool_calls,
  (SELECT json_agg(e.*) FROM wf_langgraph_events e WHERE e.run_id = r.run_id) as events,
  (SELECT row_to_json(a.*) FROM wf_assessments a WHERE a.run_id = r.run_id LIMIT 1) as assessment,
  (SELECT row_to_json(ev.*) FROM eval_evaluations ev WHERE ev.run_id = r.run_id LIMIT 1) as evaluation
FROM runs r;

-- Daily aggregates
CREATE VIEW v_daily_stats AS
SELECT
  DATE(timestamp) as date,
  COUNT(*) as total_runs,
  COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed,
  COUNT(CASE WHEN status = 'failed' THEN 1 END) as failed,
  AVG(overall_score) as avg_score,
  AVG(duration_ms) as avg_duration_ms,
  SUM(total_tokens) as total_tokens,
  SUM(total_cost) as total_cost
FROM runs
GROUP BY DATE(timestamp)
ORDER BY date DESC;
```

## MongoDB vs PostgreSQL

### Should I Keep MongoDB?

**YES - Keep both for now:**

| Use Case | Storage |
|----------|---------|
| Real-time workflow state | MongoDB (flexible schema) |
| API keys storage | MongoDB (simple key-value) |
| Analytics & reporting | PostgreSQL (SQL queries) |
| Data retention | PostgreSQL (partitioning) |
| Log archive | PostgreSQL (structured) |

### Future Migration Path

Once PostgreSQL is stable:
1. Migrate API keys to PostgreSQL (`sys_api_keys`)
2. Update frontend to read from PostgreSQL
3. Keep MongoDB for real-time state only
4. Eventually phase out MongoDB for new deployments

## Troubleshooting

### Connection Issues

```bash
# Check Heroku database status
heroku pg:info -a credit-intelligence

# Check credentials
heroku pg:credentials:url DATABASE -a credit-intelligence

# Test connection
heroku pg:psql -a credit-intelligence
```

### Schema Issues

```bash
# Reset and reinitialize (CAUTION: deletes all data)
heroku pg:reset DATABASE -a credit-intelligence
python scripts/init_postgres.py --months 12
```

### Partition Issues

```bash
# Create missing partitions
python scripts/init_postgres.py --months 12

# Check existing partitions
heroku pg:psql -a credit-intelligence
\dt *_2026_*
```
